{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf1c0bf-e9a4-43c9-a0c7-2bf3a2cee271",
   "metadata": {},
   "source": [
    "# Machine learning approach with TF-IDF\n",
    "# Feature Extraction methods in Machine Learning NLP\n",
    "# TF-IDF\n",
    "* TF-IDF (Term Frequency-Inverse Document Frequency) vectorization as a feature extraction method\n",
    "* TF-IDF is commonly used to convert text data into numerical vectors, which can then be used as input features for machine learning models.\n",
    "* This process helps capture the importance of words in a document\n",
    "# Word Embeddings\n",
    "* Convert the text data into numerical vectors using word embeddings (e.g., Word2Vec, GloVe, FastText) or contextual embeddings (e.g., BERT, GPT).\n",
    "* These embeddings capture semantic and contextual information in the text.\n",
    "\n",
    "# Machine Learning algorithms used in NLP\n",
    "* LogisticRegression : Used for text classification and sentiment analysis.\n",
    "* Naive Bayes: Used for text classification and sentiment analysis.\r",
    "* \n",
    "Support Vector Machines (SVM): Effective for text classification tasks.* \r\n",
    "Decision Trees and Random Forests: Useful for various NLP tasks, including information extraction* .\r\n",
    "Deep Learning Models: Recurrent Neural Networks (RNNs), Convolutional Neural Networks (CNNs), and Transformer-based models (e.g., BERT, GPT) are widely used for a wide range of NLP tasks due to their ability to capture complex patterns in text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d5abdf-ea6c-4367-861c-fbe5278149d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'neutral']\n",
      "Text: This is a great item. - Predicted Sentiment: negative\n",
      "Text: It's not good at all. - Predicted Sentiment: neutral\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sample data\n",
    "X_train = [\"I love this product.\", \"This is terrible.\", \"It's okay.\"]\n",
    "y_train = [\"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "X_test = [\"This is a great item.\", \"It's not good at all.\"]\n",
    "\n",
    "# Text vectorization (using TF-IDF)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "print(y_pred)\n",
    "# Print sentiment predictions\n",
    "for text, sentiment in zip(X_test, y_pred):\n",
    "    print(f\"Text: {text} - Predicted Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca94b4b4-5e01-41ff-86c0-e632c7a28da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
